{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "allied-indianapolis",
   "metadata": {},
   "source": [
    "# Ungraded Lab Part 2 - Consume a Machine Learning Model\n",
    "\n",
    "Welcome to part 2 of this ungraded lab! **Before going forward check that the server from part 1 is still running.**\n",
    "\n",
    "In this notebook you will code a minimal client that uses Python's `requests` library to interact with your server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-shield",
   "metadata": {},
   "source": [
    "## Understand the URL\n",
    "\n",
    "\n",
    "### Breaking down the URL\n",
    "\n",
    "If you played with fastAPI's client maybe you noticed that the way the requests were made was by pointing to an URL and appending some parameters to it.\n",
    "\n",
    "Your server is now hosted in the URL [http://localhost:8000/](http://localhost:8000/).\n",
    "\n",
    "The endpoint that serves your model is the `/predict` endpoint.\n",
    "\n",
    "And if you stuck with the tiny version of YOLOV3 the model used is `yolov3-tiny`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://localhost:8000'\n",
    "endpoint = '/predict'\n",
    "model = 'yolov3-tiny'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-printing",
   "metadata": {},
   "source": [
    "By appending the base URL and the endpoint you will get the full URL (without parameters) needed to consume your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_with_endpoint_no_params = base_url + endpoint\n",
    "url_with_endpoint_no_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-episode",
   "metadata": {},
   "source": [
    "To set any parameters the common syntax is to add a \"?\" character followed by the name of the parameter and its value.\n",
    "\n",
    "Let's do it and see how the final URL would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_url = url_with_endpoint_no_params + \"?model=\" + model\n",
    "full_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-concentrate",
   "metadata": {},
   "source": [
    "You might notice that this endpoint expects both a model's name and an image. But since the image is more complex it is not passed within the URL. Instead we can use the `requests` library to handle this.\n",
    "\n",
    "## Do a request to your server\n",
    "\n",
    "### Code the response_from_server function\n",
    "\n",
    "Remember that this endpoint expects a POST HTTP request. To create such request you can use the `post` function from the requests library. \n",
    "\n",
    "To pass the file along with the request, create a dictionary indicating the name of the file ('file' in this case) and the actual file.\n",
    "\n",
    "When doing a request you can check the `status code` of the response it produced. **A status code of 200 means that everything went well.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_from_server(url, image_file, verbose=True):\n",
    "    \"\"\"Makes a POST request to the server and returns the response.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL that the request is sent to.\n",
    "        image_file (_io.BufferedReader): File to upload, should be an image.\n",
    "        verbose (bool): True if the status of the response should be printed. False otherwise.\n",
    "\n",
    "    Returns:\n",
    "        requests.models.Response: Response from the server.\n",
    "    \"\"\"\n",
    "    \n",
    "    files = {'file': image_file}\n",
    "    response = requests.post(url, files=files)\n",
    "    status_code = response.status_code\n",
    "    if verbose:\n",
    "        msg = \"Everything went well!\" if status_code == 200 else \"There was an error when handling the request.\"\n",
    "        print(msg)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-receptor",
   "metadata": {},
   "source": [
    "To test this function you can open a file in your filesystem and pass it as a parameter alongside the URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"images/clock2.jpg\", \"rb\") as image_file:\n",
    "    prediction = response_from_server(full_url, image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-dynamics",
   "metadata": {},
   "source": [
    "It is great to know that the request was succesful but you are not getting any information about the objects in the image.\n",
    "\n",
    "To get the image with the bounding boxes and labels you need to parse the content of the response into an appropiate format. This process looks very similar to how you read the raw image into a cv2 image in the server.\n",
    "\n",
    "Before doing this, let's create a directory called `images_predicted` to save the image to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"images_predicted\"\n",
    "if not os.path.exists(dir_name):\n",
    "    os.mkdir(dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-genome",
   "metadata": {},
   "source": [
    "\n",
    "### Create the display_image_from_response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_from_response(response):\n",
    "    \"\"\"Display image within server's response.\n",
    "\n",
    "    Args:\n",
    "        response (requests.models.Response): The response from the server after object detection.\n",
    "    \"\"\"\n",
    "    \n",
    "    image_stream = io.BytesIO(response.content)\n",
    "    image_stream.seek(0)\n",
    "    file_bytes = np.asarray(bytearray(image_stream.read()), dtype=np.uint8)\n",
    "    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
    "    filename = \"image_with_objects.jpeg\"\n",
    "    cv2.imwrite(f'images_predicted/{filename}', image)\n",
    "    display(Image(f'images_predicted/{filename}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_from_response(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-brunei",
   "metadata": {},
   "source": [
    "Now you can consume your object detection model through your own client!\n",
    "\n",
    "Test it out on some other images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [\n",
    "    'car2.jpg',\n",
    "    'clock3.jpg',\n",
    "    'apples.jpg'\n",
    "]\n",
    "\n",
    "for image_file in image_files:\n",
    "    with open(f\"images/{image_file}\", \"rb\") as image_file:\n",
    "        prediction = response_from_server(full_url, image_file, verbose=False)\n",
    "    \n",
    "    display_image_from_response(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-albert",
   "metadata": {},
   "source": [
    "**Congratulations on finishing this ungraded lab!** Real life clients and servers have a lot more going on in terms of security and performance. However, the code you just saw is close to the one on a real production environment. We hope you feel more familiar with the process of deploying a Deep Learning model, consuming it and encourage you to keep studying.\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
